# -*- coding: utf-8 -*-
"""SVM.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pxBpQdlpADvC2MKeDosdRO-2aUOtDfXI
"""

x_ds = np.arange(0,1,0.01)
y_ds = [np.sin(2*i*np.pi)+ np.random.normal(0,0.2) for i in x_ds]
y_pr = [ np.sin(2*i*np.pi)  for i in x_ds]

print(x_ds)
print(y_ds)
print(y_pr)

import numpy as np
import matplotlib.pyplot as plt
from google.colab import files
import io
import pandas as pd
iris_= files.upload()



df=pd.read_csv(io.StringIO(iris_['IRIS.csv'].decode('utf-8')))
#df.head
SL=df.sepal_length
SW=df.sepal_width
S=df.species

sepal_length=np.array(SL)
sepal_width=np.array(SW)
species=np.array(S)

x1=[]
x_d1=[]
y1=[]
y_d1=[]

x_ds=[]
y_ds=[]

for i in range(0,50):
    if i>35:
        y_ds.append([SL[i],SW[i],S[i]])
        x_d1.append(SL[i])
        y_d1.append(SW[i])
    else:
        x_ds.append([SL[i],SW[i],S[i]])
        x1.append(SL[i])
        y1.append(SW[i])

for i in range(50,100):
    if i>85:
        y_ds.append([SL[i],SW[i],S[i]])
        x_d1.append(SL[i])
        y_d1.append(SW[i])
    else:
        x_ds.append([SL[i],SW[i],S[i]])
        x1.append(SL[i])
        y1.append(SW[i])


print(x_ds)
print(y_ds)
print(x1)
print(y1)



import numpy as np
import matplotlib.pyplot as plt
epochs = 100000
alpha = 0.7
lamda = 0.3

p = 3
w = np.random.rand(p)
b = np.random.rand(1)

#x_ds = np.arange(0,1,0.01)
#y_ds = [np.sin(2*i*np.pi)+ np.random.normal(0,0.2) for i in x_ds]
#y_pr = [ np.sin(2*i*np.pi)  for i in x_ds]

def h_svm2(w,x,b):
  result = np.dot(np.transpose(w), x) +b
  return result


def h_svm(w,x,b):
  result = np.transpose(w) *x +b
  return result

def h_s(x,w,b):
  x_i = [x**i for i in range(len(w))]
  #print(x,w,b,x_i)
  suma = sum([w[i]*x_i[i] for i in range(1,len(w))])+b
  #print(suma)
  return suma

def loss(y,x,w,C,b):
  grad_w = w**2 /2 + C * sum([max((1 -e[0])*h_svm(w,e[1],b))  for e in zip(y,x)])
  return grad_w


def L_dgrad(y,x,w,lam):
  grad_w=[]
  for i in range(len(w)):
    w_i = w[i] - sum([ lam * e[0] *e[1] for e in zip(y,x)])
    grad_w.append(w_i)
  return grad_w


def train(x_ds, y_ds,w, epochs, alpha):
  list_error = []
  time = []
  C= 1
  b=0.5

  lam = 0.2
  for i in range(epochs):
    Err = loss(y_ds,x_ds,w , C,b)
    list_error.append(Err)
    time.append(i)
    grad_w = L_dgrad(y_ds,x_ds,w,lam)
    
 

    #print(w)
    for j in range(len(grad_w)):
      if h_s(x_ds[j],w,b)>1:
        w[j] = w[j] - alpha*grad_w[j]
      else:
        w[j] = w[j] - alpha*y_ds[j]*x_ds[j]

plt.plot(x1, y1, '*')
train(x1,y1,w,100,0.000001)
plt.plot(x1, [ h_svm(i,w,b) for i in x1])
#plt.plot(x_ds,y_pr)
#print("Error MSE :" + str(error_2(y_ds, x_ds,w)+L2(y_ds,w)))
#print("Error MSE :" + str(error_abs(y_ds, x_ds,w)+L2(y_ds,w)))

p = 3
w = np.random.rand(p)
print(w)
def train2(x_ds, y_ds,w, epochs, alpha):
  list_error = []
  time = []
  C= 0.5
  b=0.5
  #b = np.random.rand(1)
  lam = 0.2
  for i in range(epochs):
    Err = loss(y_ds,x_ds,w , C,b)
    list_error.append(Err)
    time.append(i)
    grad_w = L_dgrad(y_ds,x_ds,w,lam)      
    b = np.random.rand(1)
    #print(w)
    for j in range(len(grad_w)):
      if h_s(x_ds[j],w,b)>1:
        w[j] = w[j] - alpha*grad_w[j]
      else:
        w[j] = w[j] - alpha*y_ds[j]*x_ds[j]
  
  plt.xlabel("Time")
  plt.ylabel("Loss")
  plt.plot(time, list_error)

train2(x1,y1,w,1000,0.0001)
print(w)
#plt.plot(x1, y1, '*')
#plt.plot(x1, [ h_svm(w,i,b) for i in x1])